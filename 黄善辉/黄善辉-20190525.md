# 挑战 备份日志文件  
 **挑战说明：**  
> 1. 为 shiyanlou 用户添加计划任务 
2. 每天凌晨 3 点的时候定时备份 alternatives.log到/home/shiyanlou/tmp/ 目录，并删除前一天的备份文件。  
3. 命名格式为 年-月-日，比如今天是2017年4月1日，那么文件名为 2017-04-01  

* 命令
```
$ sudo cron －f &  
$ crontab -e
0 3 * * * sudo rm /home/shiyanlou/tmp/*
0 3 * * * sudo cp /var/log/alternatives.log /home/shiyanlou/tmp/$(date +\%Y-\%m-\%d)
```
![图片描述](https://dn-simplecloud.shiyanlou.com/courses/uid1079828-20190525-1558786847291)  
![图片描述](https://dn-simplecloud.shiyanlou.com/courses/uid1079828-20190525-1558786870867)

# 实验十 命令执行顺序控制与管道

* &&和||
    > && ：前面的命令返回为0（执行成功）才执行下一条命令  
    || ：前面的命令返回不为0（执行失败）才执行下一条命令


效果如图：（which cowsay>/dev/null 指令执行不成功）
![图片描述](https://dn-simplecloud.shiyanlou.com/courses/uid1079828-20190525-1558788819004)

## 管道

* cut
![图片描述](https://dn-simplecloud.shiyanlou.com/courses/uid1079828-20190525-1558789041028)

```
# 前五个（包含第五个）
$ cut /etc/passwd -c -5
# 前五个之后的（包含第五个）
$ cut /etc/passwd -c 5-
# 第五个
$ cut /etc/passwd -c 5
# 2到5之间的（包含第五个）
$ cut /etc/passwd -c 2-5
```

* grep

```
$ grep -rnI "shiyanlou" ~
```
![图片描述](https://dn-simplecloud.shiyanlou.com/courses/uid1079828-20190525-1558789445605)


```
# 查看环境变量中以"yanlou"结尾的字符串
$ export | grep ".*yanlou$"
```
![图片描述](https://dn-simplecloud.shiyanlou.com/courses/uid1079828-20190525-1558789547676)

* wc 命令
分别只输出行数、单词数、字节数、字符数和输入文本中最长一行的字节数：
```
# 行数
$ wc -l /etc/passwd
# 单词数
$ wc -w /etc/passwd
# 字节数
$ wc -c /etc/passwd
# 字符数
$ wc -m /etc/passwd
# 最长行字节数
$ wc -L /etc/passwd
```

统计 /etc 下面所有目录数：
```
$ ls -dl /etc/*/ | wc -l
```

![图片描述](https://dn-simplecloud.shiyanlou.com/courses/uid1079828-20190525-1558789806093)


* sort 排序命令

```
字典排序
$ cat /etc/passwd | sort
反转排序
$ cat /etc/passwd | sort -r
按特定字段排序  （第三个字段，默认为字典排序）
$ cat /etc/passwd | sort -t':' -k 3
第三个字段，按数字排序 （-n）
$ cat /etc/passwd | sort -t':' -k 3 -n
```

* uniq 去重命令
 **uniq命令只能去连续重复的行，不是全文去重**
```
$ history | cut -c 8- | cut -d ' ' -f 1 | uniq
$ history | cut -c 8- | cut -d ' ' -f 1 | sort | uniq
# 或者$ history | cut -c 8- | cut -d ' ' -f 1 | sort -u

# 输出重复过的行（重复的只输出一个）及重复次数
$ history | cut -c 8- | cut -d ' ' -f 1 | sort | uniq -dc
# 输出所有重复的行
$ history | cut -c 8- | cut -d ' ' -f 1 | sort | uniq -D
```

